{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from classifier import schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifier\n",
    "\n",
    "> Classifying customer service emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file will become your README and also the index of your documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install\n",
    "\n",
    "1. Clone the repo\n",
    "2. In the terminal, navigate to the project directory\n",
    "3. Create a virtualenv with at least python version 3.11\n",
    "4. Install via `pip install '.'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why the existing model is likely failing\n",
    "\n",
    "My hypothesis is that the existing ML solution gained a lot of predictive power by utilizing specific keywords in the training corpus. Whether those keywords are predictive, or the usage of those keywords have lessened, the existing model is suffering because it essentially biased itself on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why prompting doesn't work well\n",
    "\n",
    "Prompting on a blob of email text struggles for a few likely reasons. One is that email text can be full of extraneous, inconsequential \"stuff\". Filtering text for what is essential to the conversation might help this.\n",
    "\n",
    "Another reason is that the LLM doesn't really understand these labels well. It wasn't trained to understand cardinal businesses. It is essentially a layman when it comes to CAH business process. It simply can't know what email text belongs to a category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My approach\n",
    "\n",
    "1. Load emails\n",
    "2. Prompt individual emails to remove boilerplate text (\"Summarize the conversation of this email as a series of steps\") using map-reduce (so we may handle larger than context examples).\n",
    "3. Build a chroma vector database of embedded training instances using the concatenated results of [2] and the existing labels.\n",
    "4. Query the chroma database for similar, labeled instances of data and pass them plus the summarized email to the LLM for a final prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebooks\n",
    "\n",
    "- `00_schema.ipynb` - Pydantic objects\n",
    "- `01_load.ipynb` - Load our documents from GCS\n",
    "- `02_process.ipynb` - Process emails according to step 2 above\n",
    "- `03_chroma.ipynb` - Put our email summaries into chroma\n",
    "- `04_predict.ipynb` - Predict labels\n",
    "- `05_evaluate.ipynb` - Evalute predictions\n",
    "- `06_machine_learning.ipynb` - Tried running an xgboost model over embeddings of our email summaries. Didn't work well!\n",
    "\n",
    "### Experiments\n",
    "\n",
    "Located in the `nbs/experiments` folder.\n",
    "\n",
    "- `07_split_processing.ipynb` - Split document processing between emails going into the vector store and those that are being predicted. Showed improvement in performance over baseline.\n",
    "- `08_10k_retrieval_filtering.ipynb` - Tried making prediction a '2-step' process. Identify top 3 of 11, find similar documents in that three from the vector store, then make a final prediction. Couldn't make a full run due to time constraints. On ~500 examples didn't show much improvement over experiment 7.\n",
    "\n",
    "## Performance at the moment;\n",
    "\n",
    "- Order Processing f1-store 0.82 using the process in notebook 07, macro avg of 69%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
