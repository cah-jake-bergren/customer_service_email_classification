{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10k retrieval filtering, 2-step prediction\n",
    "\n",
    "> Sample size up to 10k, create two-step prediction chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp experiments.retrieval_filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import Dict, List\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics, model_selection\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnableSequence\n",
    "from langchain.llms import VertexAI\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "\n",
    "from classifier.schema import get_embedder, get_model, quota_handler, WRITE_PREFIX, PROJECT_BUCKET\n",
    "from classifier.load import Email, get_batches, get_idx, get_emails_from_frame, \\\n",
    "    get_possible_labels, get_raw_emails, email_small_enough, write_idx\n",
    "from classifier.chroma import get_or_make_chroma\n",
    "from classifier.predict import make_prediction_prompt, get_predictions, write_predictions\n",
    "from classifier.experiments.split_processing import \\\n",
    "    format_email_for_train_summary, \\\n",
    "    format_email_for_test_summary, \\\n",
    "    make_description_from_row, batch_predict, \\\n",
    "    TRAIN_PROMPT, TEST_PROMPT\n",
    "\n",
    "EXPERIMENT_PREFIX = \"retrieval_filtering\"\n",
    "EXPERIMENT_WRITE_PREFIX = WRITE_PREFIX + \"/\" + EXPERIMENT_PREFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../../data\")\n",
    "assert data_dir.exists()\n",
    "experiment_dir = data_dir / EXPERIMENT_PREFIX\n",
    "if not experiment_dir.exists():\n",
    "    experiment_dir.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_emails = get_raw_emails()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     56096\n",
       "False     1141\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_mask = all_emails.apply(\n",
    "    lambda row: email_small_enough(\n",
    "        row.email_subject,\n",
    "        row.email_body\n",
    "    ), axis=1)\n",
    "size_mask.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter on size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56096"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_emails_filtered = all_emails[size_mask]\n",
    "all_emails_filtered.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BU</th>\n",
       "      <th>case_number</th>\n",
       "      <th>ACCOUNT_BUSINESS_UNIT__C</th>\n",
       "      <th>received_at</th>\n",
       "      <th>sfdc_category</th>\n",
       "      <th>sfdc_subcategory</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>predicted_subcategory</th>\n",
       "      <th>record_type</th>\n",
       "      <th>probability</th>\n",
       "      <th>Accuracy_upd</th>\n",
       "      <th>Bin</th>\n",
       "      <th>email_subject</th>\n",
       "      <th>email_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPD</td>\n",
       "      <td>3469839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-11T13:22:32</td>\n",
       "      <td>Order Processing</td>\n",
       "      <td>Order Entry</td>\n",
       "      <td>Order Processing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.876806</td>\n",
       "      <td>Correct</td>\n",
       "      <td>8</td>\n",
       "      <td>PO# 7004014842 || Walgreens Store 16422 || Ohi...</td>\n",
       "      <td>External Email â€“ Please use caution before o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PD</td>\n",
       "      <td>3469842</td>\n",
       "      <td>a1G4z00000H4uvREAR</td>\n",
       "      <td>2023-09-11T13:22:43</td>\n",
       "      <td>Order Processing</td>\n",
       "      <td>Order Entry</td>\n",
       "      <td>General Inquiry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.838036</td>\n",
       "      <td>Incorrect</td>\n",
       "      <td>8</td>\n",
       "      <td>Purchase Order #65398</td>\n",
       "      <td>External Email â€“ Please use caution before o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BU  case_number ACCOUNT_BUSINESS_UNIT__C          received_at  \\\n",
       "0  SPD      3469839                      NaN  2023-09-11T13:22:32   \n",
       "2   PD      3469842       a1G4z00000H4uvREAR  2023-09-11T13:22:43   \n",
       "\n",
       "      sfdc_category sfdc_subcategory predicted_category predicted_subcategory  \\\n",
       "0  Order Processing      Order Entry   Order Processing                   NaN   \n",
       "2  Order Processing      Order Entry    General Inquiry                   NaN   \n",
       "\n",
       "   record_type  probability Accuracy_upd  Bin  \\\n",
       "0            2     0.876806      Correct    8   \n",
       "2            1     0.838036    Incorrect    8   \n",
       "\n",
       "                                       email_subject  \\\n",
       "0  PO# 7004014842 || Walgreens Store 16422 || Ohi...   \n",
       "2                              Purchase Order #65398   \n",
       "\n",
       "                                          email_body  \n",
       "0  External Email â€“ Please use caution before o...  \n",
       "2  External Email â€“ Please use caution before o...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_emails_filtered.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx = model_selection.train_test_split(\n",
    "    all_emails_filtered.index.values,\n",
    "    test_size=2000,\n",
    "    train_size=8000,\n",
    "    stratify=all_emails_filtered.sfdc_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sfdc_category\n",
       " Account/Inquiry         1712\n",
       " Billing / Invoice        316\n",
       " Credits                  128\n",
       " Delivery                 258\n",
       " General Inquiry          770\n",
       " Order Discrepancy        552\n",
       " Order Processing        3235\n",
       " Pricing                   33\n",
       " Product Inquiry          426\n",
       " Program / Promotions      34\n",
       " Returns                  536\n",
       " Name: count, dtype: int64,\n",
       " sfdc_category\n",
       " Account/Inquiry         428\n",
       " Billing / Invoice        79\n",
       " Credits                  32\n",
       " Delivery                 65\n",
       " General Inquiry         193\n",
       " Order Discrepancy       138\n",
       " Order Processing        809\n",
       " Pricing                   8\n",
       " Product Inquiry         106\n",
       " Program / Promotions      8\n",
       " Returns                 134\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_emails_filtered.loc[train_idx, 'sfdc_category'].value_counts().sort_index(),\\\n",
    "all_emails_filtered.loc[test_idx, 'sfdc_category'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_idx(\n",
    "    pd.Index(train_idx),\n",
    "    pd.Index(test_idx),\n",
    "    prefix=EXPERIMENT_WRITE_PREFIX\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_emails = list(get_emails_from_frame(\n",
    "    get_raw_emails(),\n",
    "    'train',\n",
    "    index_prefix=EXPERIMENT_WRITE_PREFIX\n",
    "))\n",
    "len(training_emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load label descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions_path = data_dir / 'labels.xlsx'\n",
    "assert descriptions_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = pd.read_excel(descriptions_path).map(lambda s: s.strip() if isinstance(s, str) else s)\n",
    "descriptions_dict = descriptions.T.iloc[1:, :].apply(make_description_from_row, axis=1).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processing_chain = TRAIN_PROMPT | VertexAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Takes about 2.25 hours\n",
    "# train_summaries = []\n",
    "\n",
    "# pbar = tqdm(total=len(training_emails), ncols=80, leave=True)\n",
    "\n",
    "# try:\n",
    "#     for batch in get_batches(training_emails, 5):\n",
    "#         batch_prompts = [format_email_for_train_summary(e, descriptions_dict) for e in batch]\n",
    "#         train_summaries.extend(batch_predict(batch_prompts, train_processing_chain))\n",
    "#         pbar.update(len(batch))\n",
    "# except:\n",
    "#     pass\n",
    "# finally:\n",
    "#     pbar.close()\n",
    "\n",
    "# len(train_summaries) == len(training_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_summary_df = pd.DataFrame(\n",
    "#     zip(\n",
    "#         train_summaries,\n",
    "#         [t.idx for t in training_emails],\n",
    "#         [t.label for t in training_emails]\n",
    "#     ),\n",
    "#     columns=['summary', 'idx', 'label']\n",
    "# )\n",
    "# train_summary_df.to_csv(\n",
    "#     f'gs://{PROJECT_BUCKET}/{EXPERIMENT_WRITE_PREFIX}/split_train_summaries.csv', \n",
    "#     index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_summary_df = pd.read_csv(f'gs://{PROJECT_BUCKET}/{EXPERIMENT_WRITE_PREFIX}/split_train_summaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>idx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>**Summary**\\nThe email is about a new purchas...</td>\n",
       "      <td>40220</td>\n",
       "      <td>Order Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>**Summary:**\\nBarbara Conley, an OS&amp;D Analyst...</td>\n",
       "      <td>19920</td>\n",
       "      <td>Credits</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary    idx             label\n",
       "0   **Summary**\\nThe email is about a new purchas...  40220  Order Processing\n",
       "1   **Summary:**\\nBarbara Conley, an OS&D Analyst...  19920           Credits"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_summary_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_emails = list(get_emails_from_frame(\n",
    "    get_raw_emails(),\n",
    "    'test',\n",
    "    index_prefix=EXPERIMENT_WRITE_PREFIX\n",
    "))\n",
    "len(test_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_processing_chain = TEST_PROMPT | VertexAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▉                                        | 45/2000 [01:04<44:20,  1.36s/it]"
     ]
    }
   ],
   "source": [
    "# Takes about ~15 minutes\n",
    "test_summaries = []\n",
    "\n",
    "pbar = tqdm(total=len(test_emails), ncols=80, leave=True)\n",
    "\n",
    "try:\n",
    "    for batch in get_batches(test_emails, 5):\n",
    "        batch_prompts = [format_email_for_test_summary(e) for e in batch]\n",
    "        test_summaries.extend(batch_predict(batch_prompts, test_processing_chain))\n",
    "        pbar.update(len(batch))\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    pbar.close()\n",
    "\n",
    "len(test_summaries) == len(test_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_summary_df = pd.DataFrame(\n",
    "    zip(\n",
    "        test_summaries,\n",
    "        [t.idx for t in test_emails],\n",
    "        [t.label for t in test_emails]\n",
    "    ),\n",
    "    columns=['summary', 'idx', 'label']\n",
    ")\n",
    "test_summary_df.to_csv(\n",
    "    f'gs://{PROJECT_BUCKET}/{EXPERIMENT_WRITE_PREFIX}/split_test_summaries.csv', \n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_summary_df = pd.read_csv(f'gs://{PROJECT_BUCKET}/{EXPERIMENT_WRITE_PREFIX}/split_test_summaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_summary_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction (2-step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
