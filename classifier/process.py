# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_process.ipynb.

# %% auto 0
__all__ = ['SUMMARIZE_PROMPT_PREFIX', 'SUMMARIZE_PROMPT_STR', 'SUMMARIZE_PROMPT', 'BISON_MAXIMUM_INPUT_TOKENS',
           'CONTEXT_TOKEN_LIMIT', 'EMAIL_SUBJECT_PREFIX', 'EMAIL_BODY_PREFIX', 'PREFIX_LEN', 'make_document_from_email',
           'split_training_instance_for_summary', 'split_training_instances', 'get_email_document_summary']

# %% ../nbs/02_process.ipynb 2
from typing import List, Dict
from itertools import chain, islice

from .schema import batch_predict, predict
from .load import get_training_instances, TrainingInstance

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.prompts import PromptTemplate
from langchain.schema import Document
from tqdm.auto import tqdm

# %% ../nbs/02_process.ipynb 8
SUMMARIZE_PROMPT_PREFIX = """You are a customer service representative.
Summarize the following email, try to preserve as much information as is necessary to diagnose and solve the customers issue detailed in the email.
Think through your summary step-by-step.
Only use information present in the email.
EMAIL:
"""

SUMMARIZE_PROMPT_STR = SUMMARIZE_PROMPT_PREFIX + "{context}\nSummary:"

SUMMARIZE_PROMPT = PromptTemplate.from_template(SUMMARIZE_PROMPT_STR)

BISON_MAXIMUM_INPUT_TOKENS = 8192
CONTEXT_TOKEN_LIMIT = BISON_MAXIMUM_INPUT_TOKENS - len(SUMMARIZE_PROMPT_PREFIX)

# %% ../nbs/02_process.ipynb 10
EMAIL_SUBJECT_PREFIX = "--EMAIL SUBJECT--"
EMAIL_BODY_PREFIX = "--EMAIL BODY--"
PREFIX_LEN = len(EMAIL_SUBJECT_PREFIX + EMAIL_BODY_PREFIX) + len("\n"*4)


def make_document_from_email(
        body: str, 
        subject: str, 
        metadata: Dict[str, str]
        ) -> Document:
    return Document(
        page_content="\n".join([
            EMAIL_SUBJECT_PREFIX,
            subject,
            EMAIL_BODY_PREFIX,
            body]),
        metadata=metadata
    )


def split_training_instance_for_summary(
    training_instance: TrainingInstance,
    character_limit: int = CONTEXT_TOKEN_LIMIT
    ) -> List[Document]:
    subject_len = len(training_instance.email_subject)
    body_len = len(training_instance.email_body)
    if (subject_len + body_len + PREFIX_LEN) > character_limit:
        body_limit = character_limit - subject_len - PREFIX_LEN
        body_splitter = RecursiveCharacterTextSplitter(
            chunk_size=body_limit)
        body_texts = body_splitter.split_text(training_instance.email_body)
    else:
        body_texts = [training_instance.email_body]
    metadata = training_instance.metadata
    metadata['idx'] = training_instance.idx
    metadata['label'] = training_instance.label
    # Gather split instances as documents
    split_instances = []
    for i, body in enumerate(body_texts):
        i_metadata = metadata.copy()
        i_metadata['idx_chunk'] = i
        i_document = make_document_from_email(
            body,
            subject=training_instance.email_subject,
            metadata=i_metadata
        )
        split_instances.append(i_document)
    return split_instances


def split_training_instances(instances: List[TrainingInstance]) -> List[Document]:
    return list(chain.from_iterable(map(split_training_instance_for_summary, instances)))

# %% ../nbs/02_process.ipynb 16
def get_email_document_summary(document: Document) -> str:
    prompt = SUMMARIZE_PROMPT.format(
        context=document.page_content
    )
    summary_response = predict(prompt)
    return summary_response.text
