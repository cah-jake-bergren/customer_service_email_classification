# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_process.ipynb.

# %% auto 0
__all__ = ['EMAIL_SUBJECT_PREFIX', 'EMAIL_BODY_PREFIX', 'PREFIX_LEN', 'SPLIT_CHAIN_PROMPT_TEMPLATE', 'SPLIT_CHAIN_PROMPT',
           'SUMMARIZE_PROMPT_PREFIX', 'SUMMARIZE_PROMPT_STR', 'SUMMARIZE_PROMPT', 'BISON_MAXIMUM_INPUT_TOKENS',
           'CONTEXT_TOKEN_LIMIT', 'SUMMARIZATION_PROMPT_FILE_NAME', 'SUMMARIZATION_METADATA_FILE_NAME',
           'SUMMARIZATION_RESULT_PREFIX', 'make_document_from_instance', 'prepare_summarization_prompt',
           'prepare_batch_summarization_files', 'summarize_prompts', 'load_batch_prediction_results']

# %% ../nbs/02_process.ipynb 2
from typing import List, Dict, Any, Tuple, Iterable
from itertools import chain, islice

from .schema import batch_predict, predict, get_storage_client, \
    get_model, DEFAULT_PREDICT_PARAMS
from .load import get_training_instances, TrainingInstance, \
    PROJECT_BUCKET, WRITE_PREFIX, get_idx, get_document_batches

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.prompts import PromptTemplate
from langchain.schema import Document
from langchain.llms import VertexAI
from tqdm.auto import tqdm
from google.cloud.aiplatform import BatchPredictionJob

# %% ../nbs/02_process.ipynb 5
EMAIL_SUBJECT_PREFIX = "--EMAIL SUBJECT--"
EMAIL_BODY_PREFIX = "--EMAIL BODY--"
PREFIX_LEN = len(EMAIL_SUBJECT_PREFIX + EMAIL_BODY_PREFIX) + len("\n"*4)


def make_document_from_instance(
        instance: TrainingInstance
        ) -> Document:
    metadata = instance.metadata.copy()
    metadata['idx'] = instance.idx
    return Document(
        page_content="\n".join([
            EMAIL_SUBJECT_PREFIX,
            instance.email_subject,
            EMAIL_BODY_PREFIX,
            instance.email_body]),
        metadata=metadata
    )

# %% ../nbs/02_process.ipynb 7
SPLIT_CHAIN_PROMPT_TEMPLATE = """The following is text from an email chain.
If there is more than one email in the chain, return the positions in the text where each email starts.
If there is only a single email in the chain, return [0].
Return a list of positions in the text as integers.
---EMAIL---
{email}
---END EMAIL---
Positions:"""


SPLIT_CHAIN_PROMPT = PromptTemplate.from_template(SPLIT_CHAIN_PROMPT_TEMPLATE)

# %% ../nbs/02_process.ipynb 19
SUMMARIZE_PROMPT_PREFIX = """You are a customer service representative.
Summarize the following email, try to preserve as much information as is necessary to diagnose and solve the customers issue detailed in the email.
Think through your summary step-by-step.
Only use information present in the email.
EMAIL:
"""

SUMMARIZE_PROMPT_STR = SUMMARIZE_PROMPT_PREFIX + "{context}\nSummary:"

SUMMARIZE_PROMPT = PromptTemplate.from_template(SUMMARIZE_PROMPT_STR)

BISON_MAXIMUM_INPUT_TOKENS = 8192
CONTEXT_TOKEN_LIMIT = BISON_MAXIMUM_INPUT_TOKENS - len(SUMMARIZE_PROMPT_PREFIX)

# %% ../nbs/02_process.ipynb 22
def prepare_summarization_prompt(document: Document) -> Tuple[Dict[str, str], Dict[str, Any]]:
    prompt = {'prompt': SUMMARIZE_PROMPT.format(context=document.page_content)}
    return prompt, document.metadata

# %% ../nbs/02_process.ipynb 39
SUMMARIZATION_PROMPT_FILE_NAME = "summarization_prompts.jsonl"
SUMMARIZATION_METADATA_FILE_NAME = "summarization_metadata.jsonl"


def prepare_batch_summarization_files(
        loader: Iterable[TrainingInstance],
        bucket_name: str = PROJECT_BUCKET,
        use_pbar: bool = False,
        pbar_size: int = 10000,
        prefix: str = WRITE_PREFIX):
    client = get_storage_client()
    bucket = client.bucket(bucket_name=bucket_name)
    prompt_blob_name = f"{prefix}/{SUMMARIZATION_PROMPT_FILE_NAME}"
    metadata_blob_name = f"{prefix}/{SUMMARIZATION_METADATA_FILE_NAME}"
    prompt_blob = bucket.blob(blob_name=prompt_blob_name)
    metadata_blob = bucket.blob(blob_name=metadata_blob_name)
    if use_pbar:
        pbar = tqdm(total=pbar_size, ncols=80, leave=False)
    with metadata_blob.open("w") as metadata_f:
        with prompt_blob.open("w") as prompt_f:
            for instance in loader:
                document = make_document_from_instance(instance)
                prompt, metadata = prepare_summarization_prompt(document)
                # Write prompt to JSONL file in GCS, write metadat to similar file
                json.dump(prompt, prompt_f)
                prompt_f.write("\n")
                json.dump(metadata, metadata_f)
                metadata_f.write("\n")
                if use_pbar:
                    pbar.update(1)
    if use_pbar:
        pbar.close()

# %% ../nbs/02_process.ipynb 42
SUMMARIZATION_RESULT_PREFIX = "summarization"


def summarize_prompts(
        file_prefix: str = WRITE_PREFIX,
        file_name: str = SUMMARIZATION_PROMPT_FILE_NAME,
        bucket_name: str = PROJECT_BUCKET,
        params: Dict[str, Any] = DEFAULT_PREDICT_PARAMS
        ) -> BatchPredictionJob:
    dataset = f"gs://{bucket_name}/{file_prefix}/{file_name}"
    destination_url_prefix = f"gs://{bucket_name}/{file_prefix}/{SUMMARIZATION_RESULT_PREFIX}"
    model = get_model()
    return model.batch_predict(
        dataset=dataset,
        destination_uri_prefix=destination_url_prefix,
        # Optional:
        model_parameters=params)

# %% ../nbs/02_process.ipynb 44
def load_batch_prediction_results():
    pass
