# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_load.ipynb.

# %% auto 0
__all__ = ['RAW_EMAILS_FILE', 'TEJAS_FILE', 'LABEL_COLUMN', 'EMAIL_SIZE_LIMIT', 'INCLUSION_COUNT', 'TRAIN_IDX_NAME',
           'TEST_IDX_NAME', 'get_raw_emails', 'process_raw_emails', 'get_possible_labels', 'get_tejas_case_numbers',
           'get_raw_emails_tejas_case_numbers', 'Email', 'email_from_row', 'email_small_enough', 'get_train_test_idx',
           'write_idx', 'get_idx', 'get_emails_from_frame', 'get_batches']

# %% ../nbs/01_load.ipynb 2
from typing import Dict, Any, Iterable, List, Tuple
import pandas as pd

from pydantic import BaseModel
from sklearn.model_selection import train_test_split

from .schema import PROJECT_BUCKET, WRITE_PREFIX

# %% ../nbs/01_load.ipynb 4
RAW_EMAILS_FILE = "Last50KCases_withSubjectAndBody.xlsx"
TEJAS_FILE = "train_test_split/pd_3k_cases_cleaned.csv"

# %% ../nbs/01_load.ipynb 6
def get_raw_emails(**read_excel_kwargs) -> pd.DataFrame:
    return pd.read_excel(f'gs://{PROJECT_BUCKET}/{RAW_EMAILS_FILE}', **read_excel_kwargs)

# %% ../nbs/01_load.ipynb 7
LABEL_COLUMN = "sfdc_category"

def process_raw_emails(emails: pd.DataFrame) -> pd.DataFrame:
    emails = emails.copy().rename({LABEL_COLUMN: 'label'}, axis=1)
    emails.loc[:, 'email_subject'] = emails.email_subject.fillna("N/A").astype(str)
    emails.loc[:, 'email_body'] = emails.email_body.fillna("N/A").astype(str)
    return emails

# %% ../nbs/01_load.ipynb 9
def get_possible_labels() -> List[str]:
    labels = get_raw_emails(usecols=[LABEL_COLUMN])
    return labels[LABEL_COLUMN].unique().tolist()

# %% ../nbs/01_load.ipynb 13
def get_tejas_case_numbers() -> pd.Series:
    return pd.read_csv(f'gs://{PROJECT_BUCKET}/{TEJAS_FILE}', usecols=['case_number']).case_number

# %% ../nbs/01_load.ipynb 17
def get_raw_emails_tejas_case_numbers() -> pd.DataFrame:
    raw_emails = get_raw_emails()
    tejas_case_numbers = get_tejas_case_numbers().tolist()
    raw_emails = raw_emails[raw_emails.case_number.isin(tejas_case_numbers)]
    return raw_emails

# %% ../nbs/01_load.ipynb 21
class Email(BaseModel):
    idx: int
    label: str
    email_subject: str
    email_body: str
    metadata: Dict[str, Any]

    def to_series(self) -> pd.Series:
        data = self.metadata.copy()
        data['idx'] = self.idx
        data['label'] = self.label
        data['email_subject'] = self.email_subject
        data['email_body'] = self.email_body
        return pd.Series(data)        


def email_from_row(
        idx: int, 
        row: pd.Series,
        label_column: str = LABEL_COLUMN):
    metadata = row.drop(
        [
            label_column, 
            'email_subject',
            'email_body'
        ]).to_dict()
    return Email(
        idx=idx,
        label=row[label_column],
        email_subject=str(row.email_subject),
        email_body=str(row.email_body),
        metadata=metadata
    )

# %% ../nbs/01_load.ipynb 25
# Our prompt to summarize takes up some amount of prompt space. This is a rough limit
EMAIL_SIZE_LIMIT = 7800


def email_small_enough(subject: str, body: str, limit: int = EMAIL_SIZE_LIMIT) -> bool:
    if not isinstance(subject, str):
        subject = str(subject)
    if not isinstance(body, str):
        body = str(body)
    return (len(subject) + len(body)) < limit

# %% ../nbs/01_load.ipynb 30
INCLUSION_COUNT = 3000


def get_train_test_idx(
        data: pd.DataFrame,
        inclusion_count: int = INCLUSION_COUNT, 
        train_proportion: int = 0.8,
        label_column: str = LABEL_COLUMN,
        random_state: int = 42):
    train_count = int(round(inclusion_count * train_proportion))
    test_count = inclusion_count - train_count
    train, test = train_test_split(
        data,
        test_size=test_count, 
        train_size=train_count,
        random_state=random_state,
        stratify=data[label_column])
    input_data = pd.concat([train, test], axis=0)
    return train_test_split(
        input_data,
        test_size=1-train_proportion,
        train_size=train_proportion,
        random_state=random_state,
        stratify=input_data[label_column]
    )

# %% ../nbs/01_load.ipynb 34
TRAIN_IDX_NAME = "train_idx.csv"
TEST_IDX_NAME = "test_idx.csv"


def write_idx(
        train_idx: pd.Index, 
        test_idx: pd.Index, 
        bucket_name: str = PROJECT_BUCKET,
        prefix: str = WRITE_PREFIX):
    
    train_idx.to_series().to_csv(f"gs://{bucket_name}/{prefix}/{TRAIN_IDX_NAME}", index=False)
    test_idx.to_series().to_csv(f"gs://{bucket_name}/{prefix}/{TEST_IDX_NAME}", index=False)

# %% ../nbs/01_load.ipynb 36
def get_idx(
        bucket_name: str = PROJECT_BUCKET,
        prefix: str = WRITE_PREFIX) -> Tuple[pd.Series, pd.Series]:
    return pd.read_csv(f'gs://{bucket_name}/{prefix}/{TRAIN_IDX_NAME}').iloc[:, 0], \
        pd.read_csv(f'gs://{bucket_name}/{prefix}/{TEST_IDX_NAME}').iloc[:, 0]

# %% ../nbs/01_load.ipynb 39
def get_emails_from_frame(
        data: pd.DataFrame,
        which: str = 'both',
        bucket_name: str = PROJECT_BUCKET,
        index_prefix: str = WRITE_PREFIX,
        label_column: str = LABEL_COLUMN
) -> Iterable[Email]:
    """
    Pass a raw dataframe
    """
    if which not in ['train', 'test', 'both']:
        raise ValueError("which must be one of 'train', 'test', 'both'")
    # Load train and test idx
    train_idx, test_idx = get_idx(bucket_name=bucket_name, prefix=index_prefix)
    full_idx = pd.concat([train_idx, test_idx], axis=0, ignore_index=True)
    if which == 'train':
        data = data.loc[train_idx, :]
    elif which == 'test':
        data = data.loc[test_idx, :]
    else:  # Both
        data = data.loc[full_idx, :]
    for idx, row in data.iterrows():
        yield email_from_row(idx, row, label_column=label_column)

# %% ../nbs/01_load.ipynb 41
def get_batches(loader: Iterable[Any], batch_size: int = 32) -> Iterable[List[Any]]:
    "Get a batch of anything from an iterable."
    batch = []
    for item in loader:
        batch.append(item)
        if len(batch) >= batch_size:
            yield batch
            batch = []
    yield batch
